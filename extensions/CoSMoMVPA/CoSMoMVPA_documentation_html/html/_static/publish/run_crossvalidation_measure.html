
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Cross validation measure example</title><meta name="generator" content="MATLAB 8.5"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2016-12-01"><meta name="DC.source" content="run_crossvalidation_measure.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Cross validation measure example</h1><!--introduction--><p>This example runs cross validation with the cosmo_crossvalidation_measure function, using a classifier with n-fold crossvalidation. It shows the confusion matrices using multiple classifiers</p><div><ol><li>For CoSMoMVPA's copyright information and license terms,   #</li><li>see the COPYING file distributed with CoSMoMVPA.           #</li></ol></div><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Define data</a></li><li><a href="#2">Part 1: Use single classifier</a></li><li><a href="#3">%% Part 2: Compare multiple classifiers</a></li><li><a href="#4">Run classifications</a></li></ul></div><h2>Define data<a name="1"></a></h2><pre class="codeinput">config=cosmo_config();
data_path=fullfile(config.tutorial_data_path,<span class="string">'ak6'</span>,<span class="string">'s01'</span>);

data_fn=fullfile(data_path,<span class="string">'glm_T_stats_perrun.nii'</span>);
mask_fn=fullfile(data_path,<span class="string">'vt_mask.nii'</span>);
ds=cosmo_fmri_dataset(data_fn,<span class="string">'mask'</span>,mask_fn,<span class="keyword">...</span>
                        <span class="string">'targets'</span>,repmat(1:6,1,10),<span class="keyword">...</span>
                        <span class="string">'chunks'</span>,floor(((1:60)-1)/6)+1);

<span class="comment">% remove constant features (due to liberal masking)</span>
ds=cosmo_remove_useless_data(ds);
</pre><h2>Part 1: Use single classifier<a name="2"></a></h2><pre class="codeinput"><span class="comment">% Assign a function handle to the cosmo_crossvalidation_measure</span>
<span class="comment">% function to the variable 'measure'</span>
<span class="comment">% Hint: a function handle is a reference to a function. A function</span>
<span class="comment">%       handle to the function named 'foo' is expressed by: @foo</span>
<span class="comment">%       For more information, run: help function_handle</span>
<span class="comment">% &gt;@@&gt;</span>
measure=@cosmo_crossvalidation_measure;
<span class="comment">% &lt;@@&lt;</span>

<span class="comment">% Make a struct containing the arguments for the measure:</span>
<span class="comment">% - classifier: a function handle to cosmo_classify_lda</span>
<span class="comment">% - partitions: the output of cosmo_nfold_partitioner applied to the</span>
<span class="comment">%               dataset</span>
<span class="comment">% Assign the struct to the variable 'args'</span>
<span class="comment">% &gt;@@&gt;</span>
args=struct();
args.classifier=@cosmo_classify_lda;
args.partitions=cosmo_nfold_partitioner(ds);
<span class="comment">% &lt;@@&lt;</span>

fprintf(<span class="string">'Using the following measure:\n'</span>);
cosmo_disp(measure,<span class="string">'strlen'</span>,Inf); <span class="comment">% avoid string truncation</span>

fprintf(<span class="string">'\nUsing the following measure arguments:\n'</span>);
cosmo_disp(args);

<span class="comment">% Apply the measure to ds, with args as second argument. Assign the result</span>
<span class="comment">% to the variable 'ds_accuracy'.</span>
<span class="comment">% &gt;@@&gt;</span>
ds_accuracy=measure(ds,args);
<span class="comment">% &lt;@@&lt;</span>

<span class="comment">% Show the result</span>
fprintf(<span class="string">'\nOutput dataset (with classification accuracy)\n'</span>);
<span class="comment">% Show the contents of 'ds_accuracy' using 'cosmo_disp'</span>
<span class="comment">% &gt;@@&gt;</span>
cosmo_disp(ds_accuracy);
<span class="comment">% &lt;@@&lt;</span>
</pre><pre class="codeoutput">Using the following measure:
@cosmo_crossvalidation_measure

Using the following measure arguments:
.classifier                                                                                   
  @cosmo_classify_lda                                                                         
.partitions                                                                                   
  .train_indices                                                                              
    { [  7         [  1         [  1        ... [  1         [  1         [  1                
         8            2            2               2            2            2                
         9            3            3               3            3            3                
         :            :            :               :            :            :                
        58           58           58              58           58           52                
        59           59           59              59           59           53                
        60 ]@54x1    60 ]@54x1    60 ]@54x1       60 ]@54x1    60 ]@54x1    54 ]@54x1   }@1x10
  .test_indices                                                                               
    { [ 1    [  7    [ 13   ... [ 43    [ 49    [ 55                                          
        2       8      14         44      50      56                                          
        3       9      15         45      51      57                                          
        4      10      16         46      52      58                                          
        5      11      17         47      53      59                                          
        6 ]    12 ]    18 ]       48 ]    54 ]    60 ]   }@1x10                               

Output dataset (with classification accuracy)
.samples          
  [ 0.833 ]       
.sa               
  .labels         
    { 'accuracy' }
</pre><h2>%% Part 2: Compare multiple classifiers<a name="3"></a></h2><pre class="codeinput"><span class="comment">% This exercise shows how multiple classifiers can be run on the same</span>
<span class="comment">% data.</span>

<span class="comment">% As a cell can contain data of any type, it also supports storage of</span>
<span class="comment">% function handles. The syntax is the same as for other types; to put</span>
<span class="comment">% handles to the functions named 'foo','bar' and 'baz' in a cell,</span>
<span class="comment">% use {@foo, @bar, @baz}</span>
<span class="comment">%</span>
<span class="comment">% For this exercise, put function handles to cosmo_classify_nn,</span>
<span class="comment">% cosmo_classify_naive_bayes and cosmo_classify_lda in a cell,</span>
<span class="comment">% and assign the result to a variable</span>
<span class="comment">% named 'classifiers'</span>
<span class="comment">% (if the SVM classifier is present, it can also be put in this cell)</span>
<span class="comment">% &gt;@@&gt;</span>
classifiers={@cosmo_classify_nn,<span class="keyword">...</span>
             @cosmo_classify_naive_bayes,<span class="keyword">...</span>
             @cosmo_classify_lda};

<span class="comment">% if svm classifier is present (either libsvm or matlab's svm), use that</span>
<span class="comment">% too. The solution presented here is system-independent because it is</span>
<span class="comment">% checked first that an svm classifier is present</span>
<span class="keyword">if</span> cosmo_check_external(<span class="string">'svm'</span>,false)
    classifiers{end+1}=@cosmo_classify_svm;
<span class="keyword">end</span>
<span class="comment">% &lt;@@&lt;</span>

<span class="comment">% Print which classifiers are used</span>
nclassifiers=numel(classifiers);
classifier_names=cellfun(@func2str,classifiers,<span class="string">'UniformOutput'</span>,false);
fprintf(<span class="string">'\n\nUsing %d classifiers: %s\n'</span>, nclassifiers, <span class="keyword">...</span>
            cosmo_strjoin(classifier_names, <span class="string">', '</span>));

<span class="comment">% Set the measure (again) to a function handle to</span>
<span class="comment">% cosmo_crossvalidation_measure, and assign the result to a variable named</span>
<span class="comment">% 'measure'</span>
<span class="comment">% &gt;@@&gt;</span>
measure=@cosmo_crossvalidation_measure;
<span class="comment">% &lt;@@&lt;</span>

<span class="comment">% Make a struct containing the arguments for the measure:</span>
<span class="comment">% - partitions: the output of cosmo_nfold_partitioner applied to the</span>
<span class="comment">% - output:     set to 'predictions' to get the predictions from the</span>
<span class="comment">%               classifier</span>
<span class="comment">%               (without the 'output' field the output defaults to</span>
<span class="comment">%               classification accuracy)</span>
<span class="comment">% (Below, in the for-loop, the field 'classifier' is set for each function</span>
<span class="comment">%  handle in the cell 'classifiers')</span>

<span class="comment">% &gt;@@&gt;</span>
args=struct();
args.partitions=cosmo_nfold_partitioner(ds);
args.output=<span class="string">'predictions'</span>;
<span class="comment">% &lt;@@&lt;</span>
</pre><pre class="codeoutput">

Using 4 classifiers: cosmo_classify_nn, cosmo_classify_naive_bayes, cosmo_classify_lda, cosmo_classify_svm
</pre><h2>Run classifications<a name="4"></a></h2><p>Compute the accuracy and predictions for each classifier, and plot the confusion matrix</p><pre class="codeinput"><span class="keyword">for</span> k=1:nclassifiers
    <span class="comment">% Set the classifier function here:</span>
    <span class="comment">% assign args.classifier to the k-th classifier in the cell</span>
    <span class="comment">% 'classifiers'.</span>
    <span class="comment">% &gt;@@&gt;</span>
    args.classifier=classifiers{k};
    <span class="comment">% &lt;@@&lt;</span>

    <span class="comment">% compute predictions using the measure, and assign the result to a</span>
    <span class="comment">% variable 'predicted_ds'.</span>
    <span class="comment">% &gt;@@&gt;</span>
    predicted_ds=measure(ds,args);
    <span class="comment">% &lt;@@&lt;</span>

    <span class="comment">% compute confusion matrix using cosmo_confusion_matrix, and assign the</span>
    <span class="comment">% result to a variable 'confusion_matrix'.</span>
    <span class="comment">% &gt;@@&gt;</span>
    confusion_matrix=cosmo_confusion_matrix(predicted_ds);
    <span class="comment">% &lt;@@&lt;</span>

    <span class="comment">% compute accuracy, and store the result in a variable called</span>
    <span class="comment">% 'accuracy'</span>
    <span class="comment">% &gt;@@&gt;</span>
    sum_diag=sum(diag(confusion_matrix));
    sum_total=sum(confusion_matrix(:));
    accuracy=sum_diag/sum_total;

    <span class="comment">% alternative:</span>
    accuracy_alt=mean(predicted_ds.samples==predicted_ds.sa.targets);
    <span class="comment">% &lt;@@&lt;</span>

    <span class="comment">% visualize confusion matrix and show classification accuracy in the</span>
    <span class="comment">% title</span>
    figure();
    imagesc(confusion_matrix,[0 10])
    classifier_name=strrep(classifier_names{k},<span class="string">'_'</span>,<span class="string">' '</span>); <span class="comment">% no underscores</span>
    desc=sprintf(<span class="string">'%s: accuracy %.1f%%'</span>, classifier_name, accuracy*100);
    title(desc)


    classes = {<span class="string">'monkey'</span>,<span class="string">'lemur'</span>,<span class="string">'mallard'</span>,<span class="string">'warbler'</span>,<span class="string">'ladybug'</span>,<span class="string">'lunamoth'</span>};
    nclasses=numel(classes);
    set(gca,<span class="string">'XTick'</span>,1:nclasses,<span class="string">'XTickLabel'</span>,classes);
    set(gca,<span class="string">'YTick'</span>,1:nclasses,<span class="string">'YTickLabel'</span>,classes);
    ylabel(<span class="string">'target'</span>);
    xlabel(<span class="string">'predicted'</span>);
    colorbar

    <span class="comment">% print classificationa accuracy in terminal window</span>
    fprintf(<span class="string">'%s\n'</span>,desc);
<span class="keyword">end</span>

<span class="comment">% Note: poor performance by some classifiers does not mean that they are</span>
<span class="comment">% useless, just that they were unable to capture the distinctions between</span>
<span class="comment">% the patterns of different conditions because these distinctions were not</span>
<span class="comment">% captured by the classifier's model.</span>
</pre><pre class="codeoutput">Warning: Output option 'predictions' is deprecated and will be removed from a
future release. Please use output='winner_predictions' instead, or use
output='fold_predictions' to get predictions for each fold

This warning is shown only once, but the underlying issue may occur multiple
times. To show each warning:
 - every time:   cosmo_warning('on')
 - once:         cosmo_warning('once')
 - never:        cosmo_warning('off')
 
cosmo classify nn: accuracy 45.0%
cosmo classify naive bayes: accuracy 60.0%
cosmo classify lda: accuracy 83.3%
cosmo classify svm: accuracy 73.3%
</pre><img vspace="5" hspace="5" src="run_crossvalidation_measure_01.png" alt=""> <img vspace="5" hspace="5" src="run_crossvalidation_measure_02.png" alt=""> <img vspace="5" hspace="5" src="run_crossvalidation_measure_03.png" alt=""> <img vspace="5" hspace="5" src="run_crossvalidation_measure_04.png" alt=""> <p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2015a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Cross validation measure example
% This example runs cross validation with the
% cosmo_crossvalidation_measure function, using a classifier with n-fold
% crossvalidation.
% It shows the confusion matrices using multiple classifiers
%
% #   For CoSMoMVPA's copyright information and license terms,   #
% #   see the COPYING file distributed with CoSMoMVPA.           #

%% Define data
config=cosmo_config();
data_path=fullfile(config.tutorial_data_path,'ak6','s01');

data_fn=fullfile(data_path,'glm_T_stats_perrun.nii');
mask_fn=fullfile(data_path,'vt_mask.nii');
ds=cosmo_fmri_dataset(data_fn,'mask',mask_fn,...
                        'targets',repmat(1:6,1,10),...
                        'chunks',floor(((1:60)-1)/6)+1);

% remove constant features (due to liberal masking)
ds=cosmo_remove_useless_data(ds);
%% Part 1: Use single classifier

% Assign a function handle to the cosmo_crossvalidation_measure
% function to the variable 'measure'
% Hint: a function handle is a reference to a function. A function
%       handle to the function named 'foo' is expressed by: @foo
%       For more information, run: help function_handle
% >@@>
measure=@cosmo_crossvalidation_measure;
% <@@<

% Make a struct containing the arguments for the measure:
% - classifier: a function handle to cosmo_classify_lda
% - partitions: the output of cosmo_nfold_partitioner applied to the
%               dataset
% Assign the struct to the variable 'args'
% >@@>
args=struct();
args.classifier=@cosmo_classify_lda;
args.partitions=cosmo_nfold_partitioner(ds);
% <@@<

fprintf('Using the following measure:\n');
cosmo_disp(measure,'strlen',Inf); % avoid string truncation

fprintf('\nUsing the following measure arguments:\n');
cosmo_disp(args);

% Apply the measure to ds, with args as second argument. Assign the result
% to the variable 'ds_accuracy'.
% >@@>
ds_accuracy=measure(ds,args);
% <@@<

% Show the result
fprintf('\nOutput dataset (with classification accuracy)\n');
% Show the contents of 'ds_accuracy' using 'cosmo_disp'
% >@@>
cosmo_disp(ds_accuracy);
% <@@<

%% %% Part 2: Compare multiple classifiers

% This exercise shows how multiple classifiers can be run on the same
% data.

% As a cell can contain data of any type, it also supports storage of
% function handles. The syntax is the same as for other types; to put
% handles to the functions named 'foo','bar' and 'baz' in a cell,
% use {@foo, @bar, @baz}
%
% For this exercise, put function handles to cosmo_classify_nn,
% cosmo_classify_naive_bayes and cosmo_classify_lda in a cell,
% and assign the result to a variable
% named 'classifiers'
% (if the SVM classifier is present, it can also be put in this cell)
% >@@>
classifiers={@cosmo_classify_nn,...
             @cosmo_classify_naive_bayes,...
             @cosmo_classify_lda};

% if svm classifier is present (either libsvm or matlab's svm), use that
% too. The solution presented here is system-independent because it is
% checked first that an svm classifier is present
if cosmo_check_external('svm',false)
    classifiers{end+1}=@cosmo_classify_svm;
end
% <@@<

% Print which classifiers are used
nclassifiers=numel(classifiers);
classifier_names=cellfun(@func2str,classifiers,'UniformOutput',false);
fprintf('\n\nUsing %d classifiers: %s\n', nclassifiers, ...
            cosmo_strjoin(classifier_names, ', '));

% Set the measure (again) to a function handle to
% cosmo_crossvalidation_measure, and assign the result to a variable named
% 'measure'
% >@@>
measure=@cosmo_crossvalidation_measure;
% <@@<

% Make a struct containing the arguments for the measure:
% - partitions: the output of cosmo_nfold_partitioner applied to the
% - output:     set to 'predictions' to get the predictions from the
%               classifier
%               (without the 'output' field the output defaults to
%               classification accuracy)
% (Below, in the for-loop, the field 'classifier' is set for each function
%  handle in the cell 'classifiers')

% >@@>
args=struct();
args.partitions=cosmo_nfold_partitioner(ds);
args.output='predictions';
% <@@<

%% Run classifications
% Compute the accuracy and predictions for each classifier, and plot the
% confusion matrix
for k=1:nclassifiers
    % Set the classifier function here:
    % assign args.classifier to the k-th classifier in the cell
    % 'classifiers'.
    % >@@>
    args.classifier=classifiers{k};
    % <@@<

    % compute predictions using the measure, and assign the result to a
    % variable 'predicted_ds'.
    % >@@>
    predicted_ds=measure(ds,args);
    % <@@<

    % compute confusion matrix using cosmo_confusion_matrix, and assign the
    % result to a variable 'confusion_matrix'.
    % >@@>
    confusion_matrix=cosmo_confusion_matrix(predicted_ds);
    % <@@<

    % compute accuracy, and store the result in a variable called
    % 'accuracy'
    % >@@>
    sum_diag=sum(diag(confusion_matrix));
    sum_total=sum(confusion_matrix(:));
    accuracy=sum_diag/sum_total;

    % alternative:
    accuracy_alt=mean(predicted_ds.samples==predicted_ds.sa.targets);
    % <@@<

    % visualize confusion matrix and show classification accuracy in the
    % title
    figure();
    imagesc(confusion_matrix,[0 10])
    classifier_name=strrep(classifier_names{k},'_',' '); % no underscores
    desc=sprintf('%s: accuracy %.1f%%', classifier_name, accuracy*100);
    title(desc)


    classes = {'monkey','lemur','mallard','warbler','ladybug','lunamoth'};
    nclasses=numel(classes);
    set(gca,'XTick',1:nclasses,'XTickLabel',classes);
    set(gca,'YTick',1:nclasses,'YTickLabel',classes);
    ylabel('target');
    xlabel('predicted');
    colorbar

    % print classificationa accuracy in terminal window
    fprintf('%s\n',desc);
end

% Note: poor performance by some classifiers does not mean that they are
% useless, just that they were unable to capture the distinctions between
% the patterns of different conditions because these distinctions were not
% captured by the classifier's model.

##### SOURCE END #####
--></body></html>